{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taaha3244/AI-Agents/blob/main/L7_job_application_crew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wgNzvQKMz-I5",
        "outputId": "c201231e-87ea-4195-f9a1-bb7ce1097b38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai==0.28.8\n",
            "  Downloading crewai-0.28.8-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crewai_tools==0.1.6\n",
            "  Downloading crewai_tools-0.1.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_community==0.0.29\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (1.4.4)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (8.1.7)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.103-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting instructor<0.6.0,>=0.5.2 (from crewai==0.28.8)\n",
            "  Downloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.13.3 (from crewai==0.28.8)\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl (16 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (2.7.1)\n",
            "Collecting python-dotenv==1.0.0 (from crewai==0.28.8)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (2023.12.25)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.1.6) (4.12.3)\n",
            "Collecting chromadb<0.5.0,>=0.4.22 (from crewai_tools==0.1.6)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lancedb<0.6.0,>=0.5.4 (from crewai_tools==0.1.6)\n",
            "  Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyright<2.0.0,>=1.1.350 (from crewai_tools==0.1.6)\n",
            "  Downloading pyright-1.1.363-py3-none-any.whl (18 kB)\n",
            "Collecting pytest<9.0.0,>=8.0.0 (from crewai_tools==0.1.6)\n",
            "  Downloading pytest-8.2.1-py3-none-any.whl (339 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.6/339.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytube<16.0.0,>=15.0.0 (from crewai_tools==0.1.6)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.1.6) (2.31.0)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from crewai_tools==0.1.6)\n",
            "  Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.0.29)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain_community==0.0.29)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community==0.0.29)\n",
            "  Downloading langsmith-0.1.60-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (1.25.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (2.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.11.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.63.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.102-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.51.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading gptcache-0.1.43-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai<0.0.6,>=0.0.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Collecting pypdf<4.0.0,>=3.11.0 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.7.1)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyGithub<2.0.0,>=1.59.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython<4.0.0,>=3.1.38 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai==0.28.8)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Collecting deprecation (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.3.3)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.10/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (14.0.2)\n",
            "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpatch<2.0,>=1.33 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain-0.1.15-py3-none-any.whl (814 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m814.5/814.5 kB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.13.3->crewai==0.28.8)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.24.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (3.20.3)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.18.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai_tools==0.1.6)\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2024.2.2)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (3.0.3)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.14.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4.0.0,>=3.1.38->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.23.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.0.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai==0.28.8)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai==0.28.8)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (3.18.1)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=1.6.0->pyright<2.0.0,>=1.1.350->crewai_tools==0.1.6) (67.7.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.12)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.20.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3<3,>=1.21.1->requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (1.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp<2024.0.0,>=2023.11.14->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt_dlp<2024.0.0,>=2023.11.14->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of fastapi-cli to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
            "  Downloading fastapi_cli-0.0.2-py3-none-any.whl (9.1 kB)\n",
            "Collecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2023.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (42.0.7)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.16.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.22)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=cd201800ada4f42809ef56bef822a40e9e374cbf5a54be93706f53563f25fe93\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: schema, ratelimiter, pypika, monotonic, mmh3, brotli, websockets, uvloop, smmap, semver, pytube, python-dotenv, pysbd, pypdf, pyjwt, pycryptodomex, py, pulsar-client, packaging, overrides, outcome, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, nodeenv, mypy-extensions, mutagen, Mako, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, docstring-parser, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, yt_dlp, youtube-transcript-api, wsproto, watchfiles, uvicorn, typing-inspect, trio, tiktoken, starlette, retry, pytest, pyright, pynacl, pylance, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, marshmallow, jsonpatch, httpcore, gptcache, gitdb, deprecation, coloredlogs, alembic, trio-websocket, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, langsmith, lancedb, kubernetes, httpx, gitpython, fastapi, dataclasses-json, selenium, PyGithub, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openai, langchain-core, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-openai, langchain_community, instructor, langchain, chromadb, embedchain, crewai, crewai_tools\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "  Attempting uninstall: docstring-parser\n",
            "    Found existing installation: docstring_parser 0.16\n",
            "    Uninstalling docstring_parser-0.16:\n",
            "      Successfully uninstalled docstring_parser-0.16\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "Successfully installed Mako-1.3.5 PyGithub-1.59.1 alembic-1.13.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 brotli-1.1.0 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 crewai-0.28.8 crewai_tools-0.1.6 dataclasses-json-0.6.6 deprecated-1.2.14 deprecation-2.1.0 docstring-parser-0.15 embedchain-0.1.102 fastapi-0.110.3 gitdb-4.0.11 gitpython-3.1.43 gptcache-0.1.43 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.0.0 instructor-0.5.2 jsonpatch-1.33 jsonpointer-2.4 kubernetes-29.0.0 lancedb-0.5.7 langchain-0.1.13 langchain-core-0.1.52 langchain-openai-0.0.5 langchain-text-splitters-0.0.2 langchain_community-0.0.29 langsmith-0.1.60 marshmallow-3.21.2 mmh3-4.1.0 monotonic-1.6 mutagen-1.47.0 mypy-extensions-1.0.0 nodeenv-1.8.0 onnxruntime-1.18.0 openai-1.30.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-exporter-otlp-proto-http-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.3 outcome-1.3.0.post0 overrides-7.7.0 packaging-23.2 posthog-3.5.0 pulsar-client-3.5.0 py-1.11.0 pycryptodomex-3.20.0 pyjwt-2.8.0 pylance-0.9.18 pynacl-1.5.0 pypdf-3.17.4 pypika-0.48.9 pyright-1.1.363 pysbd-0.3.4 pytest-8.2.1 python-dotenv-1.0.0 pytube-15.0.0 ratelimiter-1.2.0.post0 retry-0.9.2 schema-0.7.7 selenium-4.21.0 semver-3.0.2 smmap-5.0.1 starlette-0.37.2 tiktoken-0.5.2 trio-0.25.1 trio-websocket-0.11.1 typing-inspect-0.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0 wsproto-1.2.0 youtube-transcript-api-0.6.2 yt_dlp-2023.12.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tavily-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xfWRBXV0hGQ",
        "outputId": "8427b924-b6b2-45e6-8927-d32fab162c1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.3.3-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tavily-python) (2.31.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.5.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->tavily-python) (2023.12.25)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (2024.2.2)\n",
            "Installing collected packages: tavily-python\n",
            "Successfully installed tavily-python-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "height": 64,
        "id": "ZaRzOuapz4aD"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzBFhBFYz4aE"
      },
      "source": [
        "- Import libraries, APIs and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "height": 30,
        "id": "xOy9Aqtsz4aE"
      },
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "height": 115,
        "id": "2TQyk5lWz4aF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"openai_api_key\")\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wpyqpFdz4aF"
      },
      "source": [
        "## crewAI Tools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.agents import Tool\n",
        "\n",
        "tool = TavilySearchResults()\n",
        "tavily= Tool(\n",
        "  name=\"Intermediate Answer\",\n",
        "  func=tool.run,\n",
        "  description=\"Useful for search-based queries\",\n",
        ")"
      ],
      "metadata": {
        "id": "ymTO_p_m3VGK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "height": 200,
        "id": "KpQz8SOBz4aG"
      },
      "outputs": [],
      "source": [
        "from crewai_tools import (\n",
        "  FileReadTool,\n",
        "  PDFSearchTool,\n",
        "  ScrapeWebsiteTool\n",
        ")\n",
        "\n",
        "search_tool = tavily\n",
        "scrape_tool = ScrapeWebsiteTool()\n",
        "read_resume = FileReadTool(file_path='/content/Muhammad_Taaha_CV (3).pdf')\n",
        "semantic_search_resume = PDFSearchTool  (pdf='/content/Muhammad_Taaha_CV (3).pdf',)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyiZAkQLz4aH"
      },
      "source": [
        "## Creating Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "height": 302,
        "id": "e7xS89msz4aI"
      },
      "outputs": [],
      "source": [
        "# Agent 1: Researcher\n",
        "researcher = Agent(\n",
        "    role=\"Tech Job Researcher\",\n",
        "    goal=\"Make sure to do amazing analysis on \"\n",
        "         \"job posting to help job applicants\",\n",
        "    tools = [scrape_tool, search_tool],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"As a Job Researcher, your prowess in \"\n",
        "        \"navigating and extracting critical \"\n",
        "        \"information from job postings is unmatched.\"\n",
        "        \"Your skills help pinpoint the necessary \"\n",
        "        \"qualifications and skills sought \"\n",
        "        \"by employers, forming the foundation for \"\n",
        "        \"effective application tailoring.\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "height": 285,
        "id": "1fodAp6yz4aI"
      },
      "outputs": [],
      "source": [
        "# Agent 2: Profiler\n",
        "profiler = Agent(\n",
        "    role=\"Personal Profiler for Engineers\",\n",
        "    goal=\"Do increditble research on job applicants \"\n",
        "         \"to help them stand out in the job market\",\n",
        "    tools = [scrape_tool, search_tool,\n",
        "             read_resume, semantic_search_resume],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"Equipped with analytical prowess, you dissect \"\n",
        "        \"and synthesize information \"\n",
        "        \"from diverse sources to craft comprehensive \"\n",
        "        \"personal and professional profiles, laying the \"\n",
        "        \"groundwork for personalized resume enhancements.\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "height": 268,
        "id": "nOdMuMmxz4aI"
      },
      "outputs": [],
      "source": [
        "# Agent 3: Resume Strategist\n",
        "resume_strategist = Agent(\n",
        "    role=\"Resume Strategist for Engineers\",\n",
        "    goal=\"Find all the best ways to make a \"\n",
        "         \"resume stand out in the job market.\",\n",
        "    tools = [scrape_tool, search_tool,\n",
        "             read_resume, semantic_search_resume],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"With a strategic mind and an eye for detail, you \"\n",
        "        \"excel at refining resumes to highlight the most \"\n",
        "        \"relevant skills and experiences, ensuring they \"\n",
        "        \"resonate perfectly with the job's requirements.\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "height": 285,
        "id": "dBnbvNoNz4aJ"
      },
      "outputs": [],
      "source": [
        "# Agent 4: Interview Preparer\n",
        "interview_preparer = Agent(\n",
        "    role=\"Engineering Interview Preparer\",\n",
        "    goal=\"Create interview questions and talking points \"\n",
        "         \"based on the resume and job requirements\",\n",
        "    tools = [scrape_tool, search_tool,\n",
        "             read_resume, semantic_search_resume],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"Your role is crucial in anticipating the dynamics of \"\n",
        "        \"interviews. With your ability to formulate key questions \"\n",
        "        \"and talking points, you prepare candidates for success, \"\n",
        "        \"ensuring they can confidently address all aspects of the \"\n",
        "        \"job they are applying for.\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxOAsM9rz4aJ"
      },
      "source": [
        "## Creating Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "height": 268,
        "id": "PVHXVxT6z4aJ"
      },
      "outputs": [],
      "source": [
        "# Task for Researcher Agent: Extract Job Requirements\n",
        "research_task = Task(\n",
        "    description=(\n",
        "        \"Analyze the job posting URL provided ({job_posting_url}) \"\n",
        "        \"to extract key skills, experiences, and qualifications \"\n",
        "        \"required. Use the tools to gather content and identify \"\n",
        "        \"and categorize the requirements.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A structured list of job requirements, including necessary \"\n",
        "        \"skills, qualifications, and experiences.\"\n",
        "    ),\n",
        "    agent=researcher,\n",
        "    async_execution=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "height": 285,
        "id": "_iB0LjTXz4aK"
      },
      "outputs": [],
      "source": [
        "# Task for Profiler Agent: Compile Comprehensive Profile\n",
        "profile_task = Task(\n",
        "    description=(\n",
        "        \"Compile a detailed personal and professional profile \"\n",
        "        \"using the GitHub ({github_url}) URLs, and personal write-up \"\n",
        "        \"({personal_writeup}). Utilize tools to extract and \"\n",
        "        \"synthesize information from these sources.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive profile document that includes skills, \"\n",
        "        \"project experiences, contributions, interests, and \"\n",
        "        \"communication style.\"\n",
        "    ),\n",
        "    agent=profiler,\n",
        "    async_execution=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BRqwgSsz4aK"
      },
      "source": [
        "- You can pass a list of tasks as `context` to a task.\n",
        "- The task then takes into account the output of those tasks in its execution.\n",
        "- The task will not run until it has the output(s) from those tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "height": 353,
        "id": "lN3X3Wmgz4aK"
      },
      "outputs": [],
      "source": [
        "# Task for Resume Strategist Agent: Align Resume with Job Requirements\n",
        "resume_strategy_task = Task(\n",
        "    description=(\n",
        "        \"Using the profile and job requirements obtained from \"\n",
        "        \"previous tasks, tailor the resume to highlight the most \"\n",
        "        \"relevant areas. Employ tools to adjust and enhance the \"\n",
        "        \"resume content. Make sure this is the best resume even but \"\n",
        "        \"don't make up any information. Update every section, \"\n",
        "        \"inlcuding the initial summary, work experience, skills, \"\n",
        "        \"and education. All to better reflrect the candidates \"\n",
        "        \"abilities and how it matches the job posting.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"An updated resume that effectively highlights the candidate's \"\n",
        "        \"qualifications and experiences relevant to the job.\"\n",
        "    ),\n",
        "    output_file=\"tailored_resume.md\",\n",
        "    context=[research_task, profile_task],\n",
        "    agent=resume_strategist\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "height": 336,
        "id": "993H1MKZz4aL"
      },
      "outputs": [],
      "source": [
        "# Task for Interview Preparer Agent: Develop Interview Materials\n",
        "interview_preparation_task = Task(\n",
        "    description=(\n",
        "        \"Create a set of potential interview questions and talking \"\n",
        "        \"points based on the tailored resume and job requirements. \"\n",
        "        \"Utilize tools to generate relevant questions and discussion \"\n",
        "        \"points. Make sure to use these question and talking points to \"\n",
        "        \"help the candiadte highlight the main points of the resume \"\n",
        "        \"and how it matches the job posting.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A document containing key questions and talking points \"\n",
        "        \"that the candidate should prepare for the initial interview.\"\n",
        "    ),\n",
        "    output_file=\"interview_materials.md\",\n",
        "    context=[research_task, profile_task, resume_strategy_task],\n",
        "    agent=interview_preparer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rat0aez4aL"
      },
      "source": [
        "## Creating the Crew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "height": 234,
        "id": "Zh48tJm3z4aL"
      },
      "outputs": [],
      "source": [
        "job_application_crew = Crew(\n",
        "    agents=[researcher,\n",
        "            profiler,\n",
        "            resume_strategist,\n",
        "            interview_preparer],\n",
        "\n",
        "    tasks=[research_task,\n",
        "           profile_task,\n",
        "           resume_strategy_task,\n",
        "           interview_preparation_task],\n",
        "\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmX0G1sbz4aL"
      },
      "source": [
        "## Running the Crew\n",
        "\n",
        "- Set the inputs for the execution of the crew."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 234,
        "id": "p7AHVY9dz4aL"
      },
      "outputs": [],
      "source": [
        "job_application_inputs = {\n",
        "    'job_posting_url': 'https://jobs.lever.co/AIFund/6c82e23e-d954-4dd8-a734-c0c2c5ee00f1?lever-origin=applied&lever-source%5B%5D=AI+Fund',\n",
        "    'github_url': 'https://github.com/taaha3244',\n",
        "    'personal_writeup': \"\"\"Taaha is an AI engineer from Pakistan\n",
        "    Highly skilled in Large Language Models, Machine \"\"\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awpDwW4Kz4aM"
      },
      "source": [
        "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "mVX62aV9z4aM",
        "outputId": "0ec379d9-4d7b-4de4-b2d5-b827c429a92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Tech Job Researcher\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Analyze the job posting URL provided (https://jobs.lever.co/AIFund/6c82e23e-d954-4dd8-a734-c0c2c5ee00f1?lever-origin=applied&lever-source%5B%5D=AI+Fund) to extract key skills, experiences, and qualifications required. Use the tools to gather content and identify and categorize the requirements.\u001b[00m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Tech Job Researcher] Task output: \n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Personal Profiler for Engineers\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Compile a detailed personal and professional profile using the GitHub (https://github.com/joaomdmoura) URLs, and personal write-up (Noah is an accomplished Software\n",
            "    Engineering Leader with 18 years of experience, specializing in\n",
            "    managing remote and in-office teams, and expert in multiple\n",
            "    programming languages and frameworks. He holds an MBA and a strong\n",
            "    background in AI and data science. Noah has successfully led\n",
            "    major tech initiatives and startups, proving his ability to drive\n",
            "    innovation and growth in the tech industry. Ideal for leadership\n",
            "    roles that require a strategic and innovative approach.). Utilize tools to extract and synthesize information from these sources.\u001b[00m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Personal Profiler for Engineers] Task output: \n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Resume Strategist for Engineers\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Using the profile and job requirements obtained from previous tasks, tailor the resume to highlight the most relevant areas. Employ tools to adjust and enhance the resume content. Make sure this is the best resume even but don't make up any information. Update every section, inlcuding the initial summary, work experience, skills, and education. All to better reflrect the candidates abilities and how it matches the job posting.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to gather as much information as possible from the provided sources to create a comprehensive personal and professional profile for Noah.\n",
            "\n",
            "Action: Read website content\n",
            "Action Input: {\"website_url\": \"https://github.com/joaomdmoura\"}\u001b[0m\u001b[95m \n",
            "\n",
            "joaomdmoura (João Moura) · GitHub\n",
            "Skip to content\n",
            "Navigation Menu\n",
            "Toggle navigation\n",
            " Sign in\n",
            " Product\n",
            "Actions\n",
            " Automate any workflow\n",
            "Packages\n",
            " Host and manage packages\n",
            "Security\n",
            " Find and fix vulnerabilities\n",
            "Codespaces\n",
            " Instant dev environments\n",
            "Copilot\n",
            " Write better code with AI\n",
            "Code review\n",
            " Manage code changes\n",
            "Issues\n",
            " Plan and track work\n",
            "Discussions\n",
            " Collaborate outside of code\n",
            "Explore\n",
            " All features\n",
            " Documentation\n",
            " GitHub Skills\n",
            " Blog\n",
            " Solutions\n",
            "For\n",
            " Enterprise\n",
            " Teams\n",
            " Startups\n",
            " Education\n",
            "By Solution\n",
            " CI/CD & Automation\n",
            " DevOps\n",
            " DevSecOps\n",
            "Resources\n",
            " Learning Pathways\n",
            " White papers, Ebooks, Webinars\n",
            " Customer Stories\n",
            " Partners\n",
            " Open Source\n",
            "GitHub Sponsors\n",
            " Fund open source developers\n",
            "The ReadME Project\n",
            " GitHub community articles\n",
            "Repositories\n",
            " Topics\n",
            " Trending\n",
            " Collections\n",
            "Pricing\n",
            "Search or jump to...\n",
            "Search code, repositories, users, issues, pull requests...\n",
            " Search\n",
            "Clear\n",
            " Search syntax tips\n",
            " Provide feedback\n",
            "We read every piece of feedback, and take your input very seriously.\n",
            "Include my email address so I can be contacted\n",
            " Cancel\n",
            " Submit feedback\n",
            " Saved searches\n",
            "Use saved searches to filter your results more quickly\n",
            "Name\n",
            "Query\n",
            " To see all available qualifiers, see our documentation.\n",
            " Cancel\n",
            " Create saved search\n",
            " Sign in\n",
            " Sign up\n",
            "You signed in with another tab or window. Reload to refresh your session.\n",
            "You signed out in another tab or window. Reload to refresh your session.\n",
            "You switched accounts on another tab or window. Reload to refresh your session.\n",
            "Dismiss alert\n",
            "joaomdmoura\n",
            "Follow\n",
            " Overview\n",
            " Repositories\n",
            " 70\n",
            " Projects\n",
            " 0\n",
            " Packages\n",
            " 0\n",
            " Stars\n",
            " 85\n",
            "Sponsoring\n",
            "1\n",
            "More\n",
            "Overview\n",
            "Repositories\n",
            "Projects\n",
            "Packages\n",
            "Stars\n",
            "Sponsoring\n",
            "joaomdmoura\n",
            "Follow\n",
            "🏠\n",
            "Working from home\n",
            " João Moura\n",
            " joaomdmoura\n",
            "🏠\n",
            "Working from home\n",
            "Follow\n",
            "Founder of crewAI / prev @clearbit (acc by @HubSpot) \n",
            "1.8k\n",
            " followers\n",
            " · \n",
            "20\n",
            " following\n",
            "@clearbit\n",
            "São Paulo, SP, Brazil\n",
            "http://joaomdmoura.com\n",
            "X\n",
            "@joaomdmoura\n",
            "Sponsoring\n",
            "Achievementsx4x3BetaSend feedbackAchievementsx4x3BetaSend feedback\n",
            "Highlights\n",
            "Developer Program Member\n",
            " Pro\n",
            "Organizations\n",
            " Block or Report\n",
            "Block or report joaomdmoura\n",
            "Block user\n",
            " Prevent this user from interacting with your repositories and sending you notifications.\n",
            " Learn more about blocking users.\n",
            " You must be logged in to block users.\n",
            " Add an optional note:\n",
            "Please don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\n",
            " Block user\n",
            "Report abuse\n",
            " Contact GitHub support about this user’s behavior.\n",
            " Learn more about reporting abuse.\n",
            "Report abuse\n",
            " Overview\n",
            " Repositories\n",
            " 70\n",
            " Projects\n",
            " 0\n",
            " Packages\n",
            " 0\n",
            " Stars\n",
            " 85\n",
            "Sponsoring\n",
            "1\n",
            "More\n",
            "Overview\n",
            "Repositories\n",
            "Projects\n",
            "Packages\n",
            "Stars\n",
            "Sponsoring\n",
            " Pinned\n",
            "crewAI\n",
            "crewAI Public\n",
            " Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\n",
            "Python\n",
            " 14.5k\n",
            " 1.9k\n",
            "machinery\n",
            "machinery Public\n",
            " Elixir State machine thin layer for structs\n",
            "Elixir\n",
            " 515\n",
            " 53\n",
            "rails-api/active_model_serializers\n",
            "rails-api/active_model_serializers Public\n",
            " ActiveModel::Serializer implementation and Rails hooks\n",
            "Ruby\n",
            " 5.3k\n",
            " 1.4k\n",
            "gioco\n",
            "gioco Public\n",
            " A gamification gem to Ruby on Rails applications\n",
            "Ruby\n",
            " 305\n",
            " 38\n",
            "sigma\n",
            "sigma Public\n",
            " A ranking algorithm implementation to Ruby on Rails applications\n",
            "Ruby\n",
            " 50\n",
            " 5\n",
            "keeper\n",
            "keeper Public\n",
            " Flexible and Simple authentication solution for Phoenix\n",
            "Elixir\n",
            " 30\n",
            " 2\n",
            " Something went wrong, please refresh the page to try again.\n",
            " If the problem persists, check the GitHub status page\n",
            " or contact support.\n",
            "Footer\n",
            " © 2024 GitHub, Inc.\n",
            "Footer navigation\n",
            "Terms\n",
            "Privacy\n",
            "Security\n",
            "Status\n",
            "Docs\n",
            "Contact\n",
            " Manage cookies\n",
            " Do not share my personal information\n",
            " You can’t perform that action at this time.\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mI need to carefully analyze the job posting URL provided and extract key skills, experiences, and qualifications required to provide a detailed list of job requirements.\n",
            "\n",
            "Action: Read website content\n",
            "Action Input: {\"website_url\": \"https://jobs.lever.co/AIFund/6c82e23e-d954-4dd8-a734-c0c2c5ee00f1?lever-origin=applied&lever-source%5B%5D=AI+Fund\"}\u001b[0m\u001b[95m \n",
            "\n",
            "career - Full Stack EngineerFull Stack EngineerColombiaAI Fund – AI Fund /Full time /Apply for this jobJob Description:We are looking for Full Stack Engineers to produce scalable software solutions for our portfolio companies. You’ll be part of a cross-functional and will be responsible for the full software development life cycle, from conception to deployment.As a Full Stack Developer, you should be comfortable around both front-end and back-end coding languages, development frameworks and third-party libraries. You should also be a team player with a knack for visual design and utility.What You Will be Doing:- Work with development teams and product managers to ideate software solutions- Build the front-end of applications through appealing visual design- Develop and manage well-functioning databases and applications- Write effective APIs- Test software to ensure responsiveness and efficiency- Troubleshoot, debug and upgrade software- Create security and data protection settings- Build features and applications What You Must Bring:Must Haves:- Proven experience as a Full Stack Developer or similar role- Experience developing desktop and mobile applications- Familiarity with common stacks- Knowledge of multiple front-end languages and libraries (e.g. HTML/ CSS, JavaScript, XML, jQuery)- Knowledge of multiple object-oriented languages (e.g. Java, Python) and multiple frameworks (e.g. Angular, React, Node.js)- Familiarity with databases (e.g. MySQL, MongoDB), web servers (e.g. Apache) and UI/UX design- Excellent communication skills and the ability to have in-depth technical discussions with both the engineering team and business people- Excellent English language skills- Self-starter and comfort working in an early-stage environment- Strong project management and organizational skillsNice to Haves:- BSc in Computer Science, Mathematics or similar field; Master’s or PhD degree is a plus- Understanding of AI/ML models- Understanding of big data tools, including Hadoop, Spark, Kafka, etc.- Proficiency in HTML, CSS and JavaScript- Experience with consumer applications and data handling- Familiarity with data privacy regulations and best practicesCharacteristics:Accountability: an obligation or willingness to accept responsibility or to account for one's actions while doing so with the highest regard for integrity.  Grit. able to stick with projects and work hard through good and bad times. High pain tolerance and can perform well under stress or pressure.Scrappy: Takes initiative and proactively gets things done with low resources, but doing creative things, begging, borrowing, and whatever is needed in an ambiguous environment or situation.Ownership orientation: Demonstrated orientation of extreme ownership over all aspects of the product and extremely results-driven in nature.We are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, and any other characteristic protected by applicable law. AI Fund believes that diversity and inclusion among our employees is critical to our success as a company, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. Selection for employment is decided on the basis of qualifications, merit, and business need.Apply for this jobJobs powered by\n",
            "\u001b[00m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mFinal Answer:\n",
            "Noah is an accomplished Software Engineering Leader with 18 years of experience, specializing in managing remote and in-office teams. He is an expert in multiple programming languages and frameworks. Noah holds an MBA and has a strong background in AI and data science. He has successfully led major tech initiatives and startups, proving his ability to drive innovation and growth in the tech industry. Ideal for leadership roles that require a strategic and innovative approach.\n",
            "\n",
            "Skills:\n",
            "- Proficient in multiple programming languages and frameworks.\n",
            "- Strong background in AI and data science.\n",
            "- Experienced in managing remote and in-office teams.\n",
            "- Strategic and innovative leadership abilities.\n",
            "\n",
            "Project Experiences:\n",
            "- Founder of crewAI, a framework for orchestrating role-playing autonomous AI agents.\n",
            "- Contributed to the development of various open-source projects in Python, Elixir, and Ruby.\n",
            "\n",
            "Contributions:\n",
            "- Developed and maintained multiple projects in Python, Elixir, and Ruby.\n",
            "- Led tech initiatives and startups successfully, driving innovation and growth in the industry.\n",
            "\n",
            "Interests:\n",
            "- Fostering collaborative intelligence through technology.\n",
            "- Exploring new ways to tackle complex tasks with AI and data science.\n",
            "- Implementing gamification strategies in software applications.\n",
            "\n",
            "Communication Style:\n",
            "- Engages in open communication to foster collaboration.\n",
            "- Articulate in presenting ideas and strategies.\n",
            "- Demonstrates strong leadership qualities in team settings.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: \n",
            "- Proven experience as a Full Stack Developer or similar role\n",
            "- Experience developing desktop and mobile applications\n",
            "- Familiarity with common stacks\n",
            "- Knowledge of multiple front-end languages and libraries (e.g. HTML/ CSS, JavaScript, XML, jQuery)\n",
            "- Knowledge of multiple object-oriented languages (e.g. Java, Python) and multiple frameworks (e.g. Angular, React, Node.js)\n",
            "- Familiarity with databases (e.g. MySQL, MongoDB), web servers (e.g. Apache) and UI/UX design\n",
            "- Excellent communication skills and the ability to have in-depth technical discussions with both the engineering team and business people\n",
            "- Excellent English language skills\n",
            "- Self-starter and comfort working in an early-stage environment\n",
            "- Strong project management and organizational skills\n",
            "- BSc in Computer Science, Mathematics or similar field; Master’s or PhD degree is a plus\n",
            "- Understanding of AI/ML models\n",
            "- Understanding of big data tools, including Hadoop, Spark, Kafka, etc.\n",
            "- Proficiency in HTML, CSS and JavaScript\n",
            "- Experience with consumer applications and data handling\n",
            "- Familiarity with data privacy regulations and best practices\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to use the information provided to update the resume to highlight the candidate's qualifications and experiences relevant to the job.\n",
            "\n",
            "Action: Read a file's content\n",
            "Action Input: {}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "# Noah Williams\n",
            "- Email: noah.williams@example.dev\n",
            "- Phone: +44 11 111 11111\n",
            "\n",
            "## Profile\n",
            "Noah Williams is a distinguished Software Engineering Leader with an 18-year tenure in the technology industry, where he has excelled in leading both remote and in-office engineering teams. His expertise spans across software development, process innovation, and enhancing team collaboration. He is highly proficient in programming languages such as Ruby, Python, JavaScript, TypeScript, and Elixir, alongside deep expertise in various front end frameworks. Noah's significant experience in data science and machine learning has enabled him to spearhead successful deployments of scalable AI solutions and innovative data model development.\n",
            "\n",
            "## Work History\n",
            "\n",
            "### DataKernel: Director of Software Engineering (remote) — 2022 - Present\n",
            "- Noah has transformed the engineering division into a key revenue pillar for DataKernel, rapidly expanding the customer base from inception to a robust community.\n",
            "- He spearheaded the integration of cutting-edge AI technologies and the use of scalable vector databases, which significantly enhanced the product's capabilities and market positioning.\n",
            "- Under his leadership, the team has seen a substantial growth in skill development, with a focus on achieving strategic project goals that have significantly influenced the company's direction.\n",
            "- Noah also played a critical role in defining the company’s long-term strategic initiatives, particularly in adopting AI technologies that have set new benchmarks within the industry.\n",
            "\n",
            "### DataKernel: Senior Software Engineering Manager (remote) — 2019 - 2022\n",
            "- Directed the engineering strategy and operations in close collaboration with C-level executives, playing a pivotal role in shaping the company's technological trajectory.\n",
            "- Managed diverse teams across multiple time zones in North America and Europe, creating an environment of transparency and mutual respect which enhanced team performance and morale.\n",
            "- His initiatives in recruiting, mentoring, and retaining top talent have been crucial in fostering a culture of continuous improvement and high performance.\n",
            "\n",
            "### InnovPet: Founder & CEO (remote) — 2019 - 2022\n",
            "- Noah founded InnovPet, a startup focused on innovative IoT solutions for pet care, including a revolutionary GPS tracking collar that significantly enhanced pet safety and owner peace of mind.\n",
            "- He was responsible for overseeing product development from concept through execution, working closely with engineering teams and marketing partners to ensure a successful market entry.\n",
            "- Successfully set up an advisory board, established production facilities overseas, and navigated the company through a successful initial funding phase, showcasing his leadership and entrepreneurial acumen.\n",
            "- Built the initial version of the product leveraging MongoDB\n",
            "\n",
            "### EliteDevs: Engineering Manager (remote) — 2018 - 2019\n",
            "- Noah was instrumental in formulating and executing strategic plans that enhanced inter-departmental coordination and trust, leading to better project outcomes.\n",
            "- He managed multiple engineering teams, fostering a culture that balances productivity with innovation, and implemented goal-setting frameworks that aligned with the company's long-term goals.\n",
            "- Was a bery hands on manager using ruby on rails and react to build out a new product.\n",
            "\n",
            "### PrintPack: Engineering Manager (remote) — 2016 - 2018\n",
            "- Led the formation and development of a high-performance engineering team that was pivotal in increasing company revenue by 500% within two years.\n",
            "- His leadership in integrating data analytics into business decision-making processes led to the development of a predictive modeling tool that revolutionized customer behavior analysis.\n",
            "\n",
            "### DriveAI: Senior Software Engineer (remote) — 2015 - 2016\n",
            "- Developed and optimized a central API that significantly improved the functionality used by a large engineering team and thousands of users, enhancing overall system performance and user satisfaction.\n",
            "- Implemented several critical enhancements, including advanced caching strategies that drastically reduced response times and system loads.\n",
            "\n",
            "### BetCraft: CTO — 2013 - 2015\n",
            "- Led the technology strategy post-Series A funding, directly reporting to the board and guiding the company through a phase of significant technological advancement and network expansion.\n",
            "- His strategic initiatives and partnerships significantly improved platform performance and expanded the company's market reach.\n",
            "- Helped build his initial product using both React and Angular and got pretty good at it.\n",
            "\n",
            "## Education\n",
            "\n",
            "### MBA in Information Technology\n",
            "London Business School - MBA\n",
            "\n",
            "### Advanced Leadership Techniques\n",
            "University of London - Certification\n",
            "\n",
            "### Data Science Specialization\n",
            "Coursera (Johns Hopkins University) - Certification\n",
            "\n",
            "### B.Sc. in Computer Science\n",
            "University of Edinburgh - Bachelor’s degree\n",
            "\n",
            "Noah Williams is an ideal candidate for senior executive roles, particularly in companies seeking leadership with a robust blend of technical and strategic expertise.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer:\n",
            "# Noah Williams\n",
            "- Email: noah.williams@example.dev\n",
            "- Phone: +44 11 111 11111\n",
            "\n",
            "## Profile\n",
            "Noah Williams is a distinguished Software Engineering Leader with an 18-year tenure in the technology industry, where he has excelled in leading both remote and in-office engineering teams. His expertise spans across software development, process innovation, and enhancing team collaboration. He is highly proficient in programming languages such as Ruby, Python, JavaScript, TypeScript, and Elixir, alongside deep expertise in various front end frameworks. Noah's significant experience in data science and machine learning has enabled him to spearhead successful deployments of scalable AI solutions and innovative data model development. He is an ideal candidate for senior executive roles, particularly in companies seeking leadership with a robust blend of technical and strategic expertise.\n",
            "\n",
            "## Work History\n",
            "\n",
            "### DataKernel: Director of Software Engineering (remote) — 2022 - Present\n",
            "- Transformed the engineering division into a key revenue pillar for DataKernel, rapidly expanding the customer base from inception to a robust community.\n",
            "- Spearheaded the integration of cutting-edge AI technologies and the use of scalable vector databases, significantly enhancing the product's capabilities and market positioning.\n",
            "- Led the team to substantial growth in skill development, focusing on achieving strategic project goals that have significantly influenced the company's direction.\n",
            "- Played a critical role in defining the company’s long-term strategic initiatives, particularly in adopting AI technologies that have set new benchmarks within the industry.\n",
            "\n",
            "### DataKernel: Senior Software Engineering Manager (remote) — 2019 - 2022\n",
            "- Directed the engineering strategy and operations in close collaboration with C-level executives, shaping the company's technological trajectory.\n",
            "- Managed diverse teams across multiple time zones in North America and Europe, creating an environment of transparency and mutual respect enhancing team performance and morale.\n",
            "- Initiatives in recruiting, mentoring, and retaining top talent have been crucial in fostering a culture of continuous improvement and high performance.\n",
            "\n",
            "### InnovPet: Founder & CEO (remote) — 2019 - 2022\n",
            "- Founded InnovPet, a startup focused on innovative IoT solutions for pet care, including a revolutionary GPS tracking collar that significantly enhanced pet safety and owner peace of mind.\n",
            "- Oversaw product development from concept through execution, working closely with engineering teams and marketing partners to ensure a successful market entry.\n",
            "- Set up an advisory board, established production facilities overseas, and navigated the company through a successful initial funding phase, showcasing leadership and entrepreneurial acumen.\n",
            "- Built the initial version of the product leveraging MongoDB\n",
            "\n",
            "### EliteDevs: Engineering Manager (remote) — 2018 - 2019\n",
            "- Formulated and executed strategic plans that enhanced inter-departmental coordination and trust, leading to better project outcomes.\n",
            "- Managed multiple engineering teams, fostering a culture that balances productivity with innovation, and implemented goal-setting frameworks that aligned with the company's long-term goals.\n",
            "- Hands-on manager using Ruby on Rails and React to build out a new product.\n",
            "\n",
            "### PrintPack: Engineering Manager (remote) — 2016 - 2018\n",
            "- Led the formation and development of a high-performance engineering team that increased company revenue by 500% within two years.\n",
            "- Integrated data analytics into business decision-making processes, leading to the development of a predictive modeling tool that revolutionized customer behavior analysis.\n",
            "\n",
            "### DriveAI: Senior Software Engineer (remote) — 2015 - 2016\n",
            "- Developed and optimized a central API that improved functionality for a large engineering team and thousands of users, enhancing overall system performance and user satisfaction.\n",
            "- Implemented critical enhancements, including advanced caching strategies that reduced response times and system loads.\n",
            "\n",
            "### BetCraft: CTO — 2013 - 2015\n",
            "- Led the technology strategy post-Series A funding, guiding the company through significant technological advancement and network expansion.\n",
            "- Strategic initiatives and partnerships improved platform performance and expanded the company's market reach.\n",
            "- Helped build the initial product using React and Angular.\n",
            "\n",
            "## Education\n",
            "\n",
            "### MBA in Information Technology\n",
            "London Business School - MBA\n",
            "\n",
            "### Advanced Leadership Techniques\n",
            "University of London - Certification\n",
            "\n",
            "### Data Science Specialization\n",
            "Coursera (Johns Hopkins University) - Certification\n",
            "\n",
            "### B.Sc. in Computer Science\n",
            "University of Edinburgh - Bachelor’s degree\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Resume Strategist for Engineers] Task output: # Noah Williams\n",
            "- Email: noah.williams@example.dev\n",
            "- Phone: +44 11 111 11111\n",
            "\n",
            "## Profile\n",
            "Noah Williams is a distinguished Software Engineering Leader with an 18-year tenure in the technology industry, where he has excelled in leading both remote and in-office engineering teams. His expertise spans across software development, process innovation, and enhancing team collaboration. He is highly proficient in programming languages such as Ruby, Python, JavaScript, TypeScript, and Elixir, alongside deep expertise in various front end frameworks. Noah's significant experience in data science and machine learning has enabled him to spearhead successful deployments of scalable AI solutions and innovative data model development. He is an ideal candidate for senior executive roles, particularly in companies seeking leadership with a robust blend of technical and strategic expertise.\n",
            "\n",
            "## Work History\n",
            "\n",
            "### DataKernel: Director of Software Engineering (remote) — 2022 - Present\n",
            "- Transformed the engineering division into a key revenue pillar for DataKernel, rapidly expanding the customer base from inception to a robust community.\n",
            "- Spearheaded the integration of cutting-edge AI technologies and the use of scalable vector databases, significantly enhancing the product's capabilities and market positioning.\n",
            "- Led the team to substantial growth in skill development, focusing on achieving strategic project goals that have significantly influenced the company's direction.\n",
            "- Played a critical role in defining the company’s long-term strategic initiatives, particularly in adopting AI technologies that have set new benchmarks within the industry.\n",
            "\n",
            "### DataKernel: Senior Software Engineering Manager (remote) — 2019 - 2022\n",
            "- Directed the engineering strategy and operations in close collaboration with C-level executives, shaping the company's technological trajectory.\n",
            "- Managed diverse teams across multiple time zones in North America and Europe, creating an environment of transparency and mutual respect enhancing team performance and morale.\n",
            "- Initiatives in recruiting, mentoring, and retaining top talent have been crucial in fostering a culture of continuous improvement and high performance.\n",
            "\n",
            "### InnovPet: Founder & CEO (remote) — 2019 - 2022\n",
            "- Founded InnovPet, a startup focused on innovative IoT solutions for pet care, including a revolutionary GPS tracking collar that significantly enhanced pet safety and owner peace of mind.\n",
            "- Oversaw product development from concept through execution, working closely with engineering teams and marketing partners to ensure a successful market entry.\n",
            "- Set up an advisory board, established production facilities overseas, and navigated the company through a successful initial funding phase, showcasing leadership and entrepreneurial acumen.\n",
            "- Built the initial version of the product leveraging MongoDB\n",
            "\n",
            "### EliteDevs: Engineering Manager (remote) — 2018 - 2019\n",
            "- Formulated and executed strategic plans that enhanced inter-departmental coordination and trust, leading to better project outcomes.\n",
            "- Managed multiple engineering teams, fostering a culture that balances productivity with innovation, and implemented goal-setting frameworks that aligned with the company's long-term goals.\n",
            "- Hands-on manager using Ruby on Rails and React to build out a new product.\n",
            "\n",
            "### PrintPack: Engineering Manager (remote) — 2016 - 2018\n",
            "- Led the formation and development of a high-performance engineering team that increased company revenue by 500% within two years.\n",
            "- Integrated data analytics into business decision-making processes, leading to the development of a predictive modeling tool that revolutionized customer behavior analysis.\n",
            "\n",
            "### DriveAI: Senior Software Engineer (remote) — 2015 - 2016\n",
            "- Developed and optimized a central API that improved functionality for a large engineering team and thousands of users, enhancing overall system performance and user satisfaction.\n",
            "- Implemented critical enhancements, including advanced caching strategies that reduced response times and system loads.\n",
            "\n",
            "### BetCraft: CTO — 2013 - 2015\n",
            "- Led the technology strategy post-Series A funding, guiding the company through significant technological advancement and network expansion.\n",
            "- Strategic initiatives and partnerships improved platform performance and expanded the company's market reach.\n",
            "- Helped build the initial product using React and Angular.\n",
            "\n",
            "## Education\n",
            "\n",
            "### MBA in Information Technology\n",
            "London Business School - MBA\n",
            "\n",
            "### Advanced Leadership Techniques\n",
            "University of London - Certification\n",
            "\n",
            "### Data Science Specialization\n",
            "Coursera (Johns Hopkins University) - Certification\n",
            "\n",
            "### B.Sc. in Computer Science\n",
            "University of Edinburgh - Bachelor’s degree\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Engineering Interview Preparer\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Create a set of potential interview questions and talking points based on the tailored resume and job requirements. Utilize tools to generate relevant questions and discussion points. Make sure to use these question and talking points to help the candiadte highlight the main points of the resume and how it matches the job posting.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mI need to gather relevant information from Noah's resume and job requirements to create interview questions and talking points.\n",
            "\n",
            "Action: Read a file's content\n",
            "Action Input: {}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "# Noah Williams\n",
            "- Email: noah.williams@example.dev\n",
            "- Phone: +44 11 111 11111\n",
            "\n",
            "## Profile\n",
            "Noah Williams is a distinguished Software Engineering Leader with an 18-year tenure in the technology industry, where he has excelled in leading both remote and in-office engineering teams. His expertise spans across software development, process innovation, and enhancing team collaboration. He is highly proficient in programming languages such as Ruby, Python, JavaScript, TypeScript, and Elixir, alongside deep expertise in various front end frameworks. Noah's significant experience in data science and machine learning has enabled him to spearhead successful deployments of scalable AI solutions and innovative data model development.\n",
            "\n",
            "## Work History\n",
            "\n",
            "### DataKernel: Director of Software Engineering (remote) — 2022 - Present\n",
            "- Noah has transformed the engineering division into a key revenue pillar for DataKernel, rapidly expanding the customer base from inception to a robust community.\n",
            "- He spearheaded the integration of cutting-edge AI technologies and the use of scalable vector databases, which significantly enhanced the product's capabilities and market positioning.\n",
            "- Under his leadership, the team has seen a substantial growth in skill development, with a focus on achieving strategic project goals that have significantly influenced the company's direction.\n",
            "- Noah also played a critical role in defining the company’s long-term strategic initiatives, particularly in adopting AI technologies that have set new benchmarks within the industry.\n",
            "\n",
            "### DataKernel: Senior Software Engineering Manager (remote) — 2019 - 2022\n",
            "- Directed the engineering strategy and operations in close collaboration with C-level executives, playing a pivotal role in shaping the company's technological trajectory.\n",
            "- Managed diverse teams across multiple time zones in North America and Europe, creating an environment of transparency and mutual respect which enhanced team performance and morale.\n",
            "- His initiatives in recruiting, mentoring, and retaining top talent have been crucial in fostering a culture of continuous improvement and high performance.\n",
            "\n",
            "### InnovPet: Founder & CEO (remote) — 2019 - 2022\n",
            "- Noah founded InnovPet, a startup focused on innovative IoT solutions for pet care, including a revolutionary GPS tracking collar that significantly enhanced pet safety and owner peace of mind.\n",
            "- He was responsible for overseeing product development from concept through execution, working closely with engineering teams and marketing partners to ensure a successful market entry.\n",
            "- Successfully set up an advisory board, established production facilities overseas, and navigated the company through a successful initial funding phase, showcasing his leadership and entrepreneurial acumen.\n",
            "- Built the initial version of the product leveraging MongoDB\n",
            "\n",
            "### EliteDevs: Engineering Manager (remote) — 2018 - 2019\n",
            "- Noah was instrumental in formulating and executing strategic plans that enhanced inter-departmental coordination and trust, leading to better project outcomes.\n",
            "- He managed multiple engineering teams, fostering a culture that balances productivity with innovation, and implemented goal-setting frameworks that aligned with the company's long-term goals.\n",
            "- Was a bery hands on manager using ruby on rails and react to build out a new product.\n",
            "\n",
            "### PrintPack: Engineering Manager (remote) — 2016 - 2018\n",
            "- Led the formation and development of a high-performance engineering team that was pivotal in increasing company revenue by 500% within two years.\n",
            "- His leadership in integrating data analytics into business decision-making processes led to the development of a predictive modeling tool that revolutionized customer behavior analysis.\n",
            "\n",
            "### DriveAI: Senior Software Engineer (remote) — 2015 - 2016\n",
            "- Developed and optimized a central API that significantly improved the functionality used by a large engineering team and thousands of users, enhancing overall system performance and user satisfaction.\n",
            "- Implemented several critical enhancements, including advanced caching strategies that drastically reduced response times and system loads.\n",
            "\n",
            "### BetCraft: CTO — 2013 - 2015\n",
            "- Led the technology strategy post-Series A funding, directly reporting to the board and guiding the company through a phase of significant technological advancement and network expansion.\n",
            "- His strategic initiatives and partnerships significantly improved platform performance and expanded the company's market reach.\n",
            "- Helped build his initial product using both React and Angular and got pretty good at it.\n",
            "\n",
            "## Education\n",
            "\n",
            "### MBA in Information Technology\n",
            "London Business School - MBA\n",
            "\n",
            "### Advanced Leadership Techniques\n",
            "University of London - Certification\n",
            "\n",
            "### Data Science Specialization\n",
            "Coursera (Johns Hopkins University) - Certification\n",
            "\n",
            "### B.Sc. in Computer Science\n",
            "University of Edinburgh - Bachelor’s degree\n",
            "\n",
            "Noah Williams is an ideal candidate for senior executive roles, particularly in companies seeking leadership with a robust blend of technical and strategic expertise.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer:\n",
            "Based on Noah Williams' extensive experience and expertise, here are some potential interview questions and talking points tailored to his resume and the job requirements:\n",
            "\n",
            "1. Can you walk us through your experience in transforming engineering divisions into revenue pillars and expanding customer bases?\n",
            "2. How have you integrated cutting-edge AI technologies and scalable databases to enhance product capabilities in your previous roles?\n",
            "3. Describe a time when you led a team to achieve substantial growth in skill development while focusing on strategic project goals.\n",
            "4. How do you approach defining long-term strategic initiatives, particularly in adopting AI technologies?\n",
            "5. What strategies have you implemented to recruit, mentor, and retain top talent in your teams?\n",
            "6. Can you discuss your experience in founding and leading a startup focused on IoT solutions and product development?\n",
            "7. How have you leveraged MongoDB in building initial product versions, and what challenges did you face?\n",
            "8. Share an example where you formulated and executed strategic plans that enhanced inter-departmental coordination and trust.\n",
            "9. Explain your approach to managing multiple engineering teams while fostering a culture of productivity and innovation.\n",
            "10. Walk us through a project where you led the formation of a high-performance engineering team and significantly increased company revenue.\n",
            "11. How have you integrated data analytics into business decision-making processes to revolutionize customer behavior analysis?\n",
            "12. Describe a scenario where you optimized a central API to enhance functionality for a large engineering team and users.\n",
            "13. Can you elaborate on your role in leading technology strategies post-funding and guiding companies through technological advancements?\n",
            "14. Share insights on how you improved platform performance and expanded market reach through strategic initiatives and partnerships.\n",
            "15. Discuss your experience in building products using React, Angular, Ruby, Python, JavaScript, TypeScript, and Elixir, and how you keep up with evolving technologies.\n",
            "\n",
            "These questions and talking points aim to highlight Noah's leadership, technical skills, strategic acumen, and innovative approach, aligning with the job requirements for a Full Stack Developer role with expertise in AI, data science, and team management.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Engineering Interview Preparer] Task output: Based on Noah Williams' extensive experience and expertise, here are some potential interview questions and talking points tailored to his resume and the job requirements:\n",
            "\n",
            "1. Can you walk us through your experience in transforming engineering divisions into revenue pillars and expanding customer bases?\n",
            "2. How have you integrated cutting-edge AI technologies and scalable databases to enhance product capabilities in your previous roles?\n",
            "3. Describe a time when you led a team to achieve substantial growth in skill development while focusing on strategic project goals.\n",
            "4. How do you approach defining long-term strategic initiatives, particularly in adopting AI technologies?\n",
            "5. What strategies have you implemented to recruit, mentor, and retain top talent in your teams?\n",
            "6. Can you discuss your experience in founding and leading a startup focused on IoT solutions and product development?\n",
            "7. How have you leveraged MongoDB in building initial product versions, and what challenges did you face?\n",
            "8. Share an example where you formulated and executed strategic plans that enhanced inter-departmental coordination and trust.\n",
            "9. Explain your approach to managing multiple engineering teams while fostering a culture of productivity and innovation.\n",
            "10. Walk us through a project where you led the formation of a high-performance engineering team and significantly increased company revenue.\n",
            "11. How have you integrated data analytics into business decision-making processes to revolutionize customer behavior analysis?\n",
            "12. Describe a scenario where you optimized a central API to enhance functionality for a large engineering team and users.\n",
            "13. Can you elaborate on your role in leading technology strategies post-funding and guiding companies through technological advancements?\n",
            "14. Share insights on how you improved platform performance and expanded market reach through strategic initiatives and partnerships.\n",
            "15. Discuss your experience in building products using React, Angular, Ruby, Python, JavaScript, TypeScript, and Elixir, and how you keep up with evolving technologies.\n",
            "\n",
            "These questions and talking points aim to highlight Noah's leadership, technical skills, strategic acumen, and innovative approach, aligning with the job requirements for a Full Stack Developer role with expertise in AI, data science, and team management.\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ],
      "source": [
        "### this execution will take a few minutes to run\n",
        "result = job_application_crew.kickoff(inputs=job_application_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYq9A6-gz4aM"
      },
      "source": [
        "- Dislplay the generated `tailored_resume.md` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "31Ve4a3iz4aM",
        "outputId": "7e9831c6-f87d-4096-b3c3-770cd2796e3f"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Noah Williams\n",
              "- Email: noah.williams@example.dev\n",
              "- Phone: +44 11 111 11111\n",
              "\n",
              "## Profile\n",
              "Noah Williams is a distinguished Software Engineering Leader with an 18-year tenure in the technology industry, where he has excelled in leading both remote and in-office engineering teams. His expertise spans across software development, process innovation, and enhancing team collaboration. He is highly proficient in programming languages such as Ruby, Python, JavaScript, TypeScript, and Elixir, alongside deep expertise in various front end frameworks. Noah's significant experience in data science and machine learning has enabled him to spearhead successful deployments of scalable AI solutions and innovative data model development. He is an ideal candidate for senior executive roles, particularly in companies seeking leadership with a robust blend of technical and strategic expertise.\n",
              "\n",
              "## Work History\n",
              "\n",
              "### DataKernel: Director of Software Engineering (remote) — 2022 - Present\n",
              "- Transformed the engineering division into a key revenue pillar for DataKernel, rapidly expanding the customer base from inception to a robust community.\n",
              "- Spearheaded the integration of cutting-edge AI technologies and the use of scalable vector databases, significantly enhancing the product's capabilities and market positioning.\n",
              "- Led the team to substantial growth in skill development, focusing on achieving strategic project goals that have significantly influenced the company's direction.\n",
              "- Played a critical role in defining the company’s long-term strategic initiatives, particularly in adopting AI technologies that have set new benchmarks within the industry.\n",
              "\n",
              "### DataKernel: Senior Software Engineering Manager (remote) — 2019 - 2022\n",
              "- Directed the engineering strategy and operations in close collaboration with C-level executives, shaping the company's technological trajectory.\n",
              "- Managed diverse teams across multiple time zones in North America and Europe, creating an environment of transparency and mutual respect enhancing team performance and morale.\n",
              "- Initiatives in recruiting, mentoring, and retaining top talent have been crucial in fostering a culture of continuous improvement and high performance.\n",
              "\n",
              "### InnovPet: Founder & CEO (remote) — 2019 - 2022\n",
              "- Founded InnovPet, a startup focused on innovative IoT solutions for pet care, including a revolutionary GPS tracking collar that significantly enhanced pet safety and owner peace of mind.\n",
              "- Oversaw product development from concept through execution, working closely with engineering teams and marketing partners to ensure a successful market entry.\n",
              "- Set up an advisory board, established production facilities overseas, and navigated the company through a successful initial funding phase, showcasing leadership and entrepreneurial acumen.\n",
              "- Built the initial version of the product leveraging MongoDB\n",
              "\n",
              "### EliteDevs: Engineering Manager (remote) — 2018 - 2019\n",
              "- Formulated and executed strategic plans that enhanced inter-departmental coordination and trust, leading to better project outcomes.\n",
              "- Managed multiple engineering teams, fostering a culture that balances productivity with innovation, and implemented goal-setting frameworks that aligned with the company's long-term goals.\n",
              "- Hands-on manager using Ruby on Rails and React to build out a new product.\n",
              "\n",
              "### PrintPack: Engineering Manager (remote) — 2016 - 2018\n",
              "- Led the formation and development of a high-performance engineering team that increased company revenue by 500% within two years.\n",
              "- Integrated data analytics into business decision-making processes, leading to the development of a predictive modeling tool that revolutionized customer behavior analysis.\n",
              "\n",
              "### DriveAI: Senior Software Engineer (remote) — 2015 - 2016\n",
              "- Developed and optimized a central API that improved functionality for a large engineering team and thousands of users, enhancing overall system performance and user satisfaction.\n",
              "- Implemented critical enhancements, including advanced caching strategies that reduced response times and system loads.\n",
              "\n",
              "### BetCraft: CTO — 2013 - 2015\n",
              "- Led the technology strategy post-Series A funding, guiding the company through significant technological advancement and network expansion.\n",
              "- Strategic initiatives and partnerships improved platform performance and expanded the company's market reach.\n",
              "- Helped build the initial product using React and Angular.\n",
              "\n",
              "## Education\n",
              "\n",
              "### MBA in Information Technology\n",
              "London Business School - MBA\n",
              "\n",
              "### Advanced Leadership Techniques\n",
              "University of London - Certification\n",
              "\n",
              "### Data Science Specialization\n",
              "Coursera (Johns Hopkins University) - Certification\n",
              "\n",
              "### B.Sc. in Computer Science\n",
              "University of Edinburgh - Bachelor’s degree"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "display(Markdown(\"./tailored_resume.md\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmuMtGUnz4aN"
      },
      "source": [
        "- Dislplay the generated `interview_materials.md` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "laJLBw_Jz4aN",
        "outputId": "2cb7f16f-a250-4d76-c3f2-bc6f75202ce2"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on Noah Williams' extensive experience and expertise, here are some potential interview questions and talking points tailored to his resume and the job requirements:\n",
              "\n",
              "1. Can you walk us through your experience in transforming engineering divisions into revenue pillars and expanding customer bases?\n",
              "2. How have you integrated cutting-edge AI technologies and scalable databases to enhance product capabilities in your previous roles?\n",
              "3. Describe a time when you led a team to achieve substantial growth in skill development while focusing on strategic project goals.\n",
              "4. How do you approach defining long-term strategic initiatives, particularly in adopting AI technologies?\n",
              "5. What strategies have you implemented to recruit, mentor, and retain top talent in your teams?\n",
              "6. Can you discuss your experience in founding and leading a startup focused on IoT solutions and product development?\n",
              "7. How have you leveraged MongoDB in building initial product versions, and what challenges did you face?\n",
              "8. Share an example where you formulated and executed strategic plans that enhanced inter-departmental coordination and trust.\n",
              "9. Explain your approach to managing multiple engineering teams while fostering a culture of productivity and innovation.\n",
              "10. Walk us through a project where you led the formation of a high-performance engineering team and significantly increased company revenue.\n",
              "11. How have you integrated data analytics into business decision-making processes to revolutionize customer behavior analysis?\n",
              "12. Describe a scenario where you optimized a central API to enhance functionality for a large engineering team and users.\n",
              "13. Can you elaborate on your role in leading technology strategies post-funding and guiding companies through technological advancements?\n",
              "14. Share insights on how you improved platform performance and expanded market reach through strategic initiatives and partnerships.\n",
              "15. Discuss your experience in building products using React, Angular, Ruby, Python, JavaScript, TypeScript, and Elixir, and how you keep up with evolving technologies.\n",
              "\n",
              "These questions and talking points aim to highlight Noah's leadership, technical skills, strategic acumen, and innovative approach, aligning with the job requirements for a Full Stack Developer role with expertise in AI, data science, and team management."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(\"./interview_materials.md\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pILu2u6Rz4aN"
      },
      "source": [
        "# CONGRATULATIONS!!!\n",
        "\n",
        "## Share your accomplishment!\n",
        "- Once you finish watching all the videos, you will see the \"In progress\" image on the bottom left turn into \"Accomplished\".\n",
        "- Click on \"Accomplished\" to view the course completion page with your name on it.\n",
        "- Take a screenshot and share on LinkedIn, X (Twitter), or Facebook.  \n",
        "- **Tag @Joāo (Joe) Moura, @crewAI, and @DeepLearning.AI, (and a few of your friends if you'd like them to try out the course)**\n",
        "- **Joāo and DeepLearning.AI will \"like\"/reshare/comment on your post!**\n",
        "\n",
        "## Get a completion badge that you can add to your LinkedIn profile!\n",
        "- Go to [learn.crewai.com](https://learn.crewai.com).\n",
        "- Upload your screenshot of your course completion page.\n",
        "- You'll get a badge from CrewAI that you can share!\n",
        "\n",
        "(Joāo will also talk about this in the last video of the course.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "DA7WaFFhz4aO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}